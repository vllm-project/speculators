"""
Configuration classes for speculative decoding implementations.

This module provides Pydantic-based configuration classes for the Speculators library,
enabling validation, serialization, and deserialization of speculative decoding
configurations. The classes extend Hugging Face's PretrainedConfig for seamless
integration with the transformers ecosystem while supporting custom speculator
model implementations, token proposal methods, and verifier compatibility validation.
"""

from __future__ import annotations

import os
from importlib.metadata import version
from typing import Any, ClassVar, cast

from pydantic import BaseModel, ConfigDict, Field
from transformers import PretrainedConfig, PreTrainedModel

from speculators.utils import (
    PydanticClassRegistryMixin,
    ReloadableBaseModel,
    load_model_config,
)

__all__ = [
    "SpeculatorModelConfig",
    "SpeculatorsConfig",
    "TokenProposalConfig",
    "VerifierConfig",
    "reload_and_populate_configs",
]


class TokenProposalConfig(PydanticClassRegistryMixin):
    """
    Base configuration for token proposal methods in speculative decoding.

    Defines how tokens are generated by the speculator, passed to the verifier,
    and scored for acceptance or rejection. All token proposal implementations
    must inherit from this class and set a unique proposal_type value.

    :cvar auto_package: Package path for automatic class discovery
    :cvar registry_auto_discovery: Enable automatic registry population
    :cvar schema_discriminator: Field used for discriminating subclass types
    """

    @classmethod
    def __pydantic_schema_base_type__(cls) -> type[TokenProposalConfig]:
        if cls.__name__ == "TokenProposalConfig":
            return cls

        return TokenProposalConfig

    auto_package: ClassVar[str] = "speculators.proposals"
    registry_auto_discovery: ClassVar[bool] = True
    schema_discriminator: ClassVar[str] = "proposal_type"

    proposal_type: str = Field(
        description=(
            "The type of token proposal method. "
            "Must be a supported proposal type from the Speculators library."
        ),
    )


class VerifierConfig(BaseModel):
    """
    Configuration for verifier models with compatibility validation.

    Defines parameters required to load verifier models or validate compatibility
    with new verifiers based on architecture and tokenizer properties. Provides
    convenience methods to extract parameters from PretrainedConfig objects.
    """

    @classmethod
    def from_pretrained(
        cls,
        config: str | os.PathLike | PreTrainedModel | PretrainedConfig | dict | None,
        name_or_path: str | None = "UNSET",
        **kwargs,
    ) -> VerifierConfig:
        """
        Create a VerifierConfig from a PretrainedConfig object.

        Extracts required parameters from the original verifier config and creates
        a VerifierConfig instance for compatibility validation.

        :param config: The configuration source to extract parameters from
        :param name_or_path: The name or path for the verifier model
        :param kwargs: Additional keyword arguments for config loading
        :return: A VerifierConfig object with extracted parameters
        """
        # Get the PretrainedConfig object if we can
        config_pretrained: PretrainedConfig | dict = (
            load_model_config(config, **kwargs)
            if config and not isinstance(config, dict)
            else cast("dict", config or {})
        )
        # Convert PretrainedConfig to dict if possible, otherwise use the original
        config_dict: dict = (
            config_pretrained.to_dict()
            if config_pretrained and isinstance(config_pretrained, PretrainedConfig)
            else cast("dict", config_pretrained)
        )
        if not config_dict:
            config_dict = {}

        if name_or_path == "UNSET":
            # name_or_path wasn't passed in, resolve it from config
            config_name_or_path = (
                getattr(config, "name_or_path", None) if config else None
            )
            config_dict_name_or_path = config_dict.get(
                "name_or_path"
            ) or config_dict.get("_name_or_path")
            name_or_path = config_name_or_path or config_dict_name_or_path

        return cls(
            name_or_path=name_or_path,
            architectures=config_dict.get("architectures", []),
        )

    name_or_path: str | None = Field(
        description=(
            "The name as a Hugging Face model ID or path to the verifier model. "
            "Used to dynamically load the verifier model for the speculator."
        ),
    )
    architectures: list[str] = Field(
        description=(
            "The model architectures from the verifier's config.json file. "
            "Used to validate architecture compatibility between verifiers."
        ),
    )


class SpeculatorsConfig(ReloadableBaseModel):
    """
    Configuration for speculative decoding algorithm implementations.

    Defines parameters required for speculative decoding algorithms including
    algorithm type, supported token proposal methods, and verifier configuration.
    """

    algorithm: str = Field(
        description=(
            "The speculative decoding algorithm implementation name. "
            "Must be a supported algorithm from the Speculators library."
        ),
    )
    proposal_methods: list[TokenProposalConfig] = Field(
        description=(
            "Token proposal methods supported by the speculator. "
            "List of proposal configurations from the Speculators library."
        ),
    )
    default_proposal_method: str = Field(
        description=(
            "Default token proposal method when none specified. "
            "Must match a proposal_type from the proposal_methods list."
        ),
    )
    verifier: VerifierConfig = Field(
        description=(
            "Configuration for the associated verifier model. "
            "Used for auto-loading and compatibility validation."
        ),
    )


class SpeculatorModelConfig(PydanticClassRegistryMixin, PretrainedConfig):
    """
    Configuration for speculator models with transformers compatibility.

    Defines hyperparameters and settings for speculator model implementations,
    including model architecture details and speculative decoding configuration.
    Inherits from PretrainedConfig for full compatibility with transformers
    ecosystem while supporting custom speculator functionality.

    :cvar model_type: The transformers model type identifier
    :cvar auto_package: Package path for automatic class discovery
    :cvar registry_auto_discovery: Enable automatic registry population
    :cvar schema_discriminator: Field used for discriminating subclass types
    """

    @classmethod
    def from_pretrained(
        cls,
        pretrained_model_name_or_path: str | os.PathLike,
        cache_dir: str | os.PathLike | None = None,
        force_download: bool = False,
        local_files_only: bool = False,
        token: str | bool | None = None,
        revision: str = "main",
        **kwargs,
    ) -> SpeculatorModelConfig:
        """
        Load a SpeculatorModelConfig from Hugging Face Hub or local directory.

        Automatically instantiates the correct config class from speculators.models
        package based on the configuration content.

        :param pretrained_model_name_or_path: Model name or path to load from
        :param cache_dir: Directory to cache the configuration
        :param force_download: Force download from Hub instead of using cache
        :param local_files_only: Use only local files, no Hub downloads
        :param token: Authentication token for Hub access
        :param revision: Model revision to load from Hub
        :param kwargs: Additional arguments for configuration loading
        :return: A SpeculatorModelConfig instance with loaded parameters
        """
        # Transformers config loading
        config_dict, kwargs = cls.get_config_dict(
            pretrained_model_name_or_path,
            cache_dir=cache_dir,
            force_download=force_download,
            local_files_only=local_files_only,
            token=token,
            revision=revision,
            **kwargs,
        )

        if "speculators_model_type" not in config_dict:
            # Conversion pathway
            raise NotImplementedError(
                "Loading a non-speculator model config is not supported yet."
            )

        return cls.from_dict(config_dict, **kwargs)

    @classmethod
    def from_dict(cls, config_dict: dict[str, Any], **kwargs) -> SpeculatorModelConfig:
        """
        Create SpeculatorModelConfig from dictionary with automatic subclass selection.

        Instantiates the appropriate subclass based on the speculators_model_type
        field in the configuration dictionary.

        :param config_dict: Dictionary containing the configuration parameters
        :param kwargs: Additional keyword arguments that override config values
        :return: A SpeculatorModelConfig instance of the appropriate subclass
        """
        dict_obj = {**config_dict, **kwargs}

        if "speculators_model_type" not in dict_obj:
            raise ValueError(
                "The config dictionary must contain the 'speculators_model_type' field "
                "for loading a SpeculatorModelConfig in the Speculators library."
            )

        return cls.model_validate(dict_obj)

    @classmethod
    def __pydantic_schema_base_type__(cls) -> type[SpeculatorModelConfig]:
        if cls.__name__ == "SpeculatorModelConfig":
            return cls

        return SpeculatorModelConfig

    # Pydantic configuration
    model_config = ConfigDict(arbitrary_types_allowed=True, extra="allow")

    # Registry configuration
    auto_package: ClassVar[str] = "speculators.models"
    registry_auto_discovery: ClassVar[bool] = True
    schema_discriminator: ClassVar[str] = "speculators_model_type"

    # PretrainedConfig class attributes
    model_type: ClassVar[str] = "speculator_model"  # type: ignore[misc]
    base_config_key: ClassVar[str] = ""  # type: ignore[misc]
    sub_configs: ClassVar[dict[str, type[PretrainedConfig]]] = {}  # type: ignore[misc,assignment]
    is_composition: ClassVar[bool] = False  # type: ignore[misc]
    attribute_map: ClassVar[dict[str, str]] = {}  # type: ignore[misc]
    base_model_tp_plan: ClassVar[dict[str, Any] | None] = None  # type: ignore[misc]
    base_model_pp_plan: ClassVar[dict[str, tuple[list[str]]] | None] = None  # type: ignore[misc]
    _auto_class: ClassVar[str | None] = ""  # type: ignore[misc]

    # Speculator model instance attributes
    speculators_model_type: str = Field(
        default="",
        description="The type of model from the Speculators repo this config is for.",
    )
    speculators_version: str = Field(
        default=version("speculators"),
        description="Version of the speculators library",
    )
    speculators_config: SpeculatorsConfig = Field(  # type: ignore[assignment]
        default=None,
        description=(
            "The speculators config describing what the model implements and creation. "
            "Contains information about the algorithm, proposal methods, and verifier."
        ),
    )

    def __init__(self, **kwargs):
        """
        Initialize a SpeculatorModelConfig instance.

        Combines Pydantic validation with transformers PretrainedConfig
        initialization for dual compatibility.

        :param kwargs: Configuration parameters for the speculator model
        """
        # initialize the Pydantic arguments first to set all valid fields
        PydanticClassRegistryMixin.__init__(self, **kwargs)

        # reset kwargs handled by Pydantic so PretrainedConfig doesn't override
        for field in self.__class__.model_fields:
            kwargs[field] = getattr(self, field)

        # initialize the Hugging Face PretrainedConfig arguments for the model
        PretrainedConfig.__init__(self, **kwargs)

        # ensure we always update the transformers version
        self.transformers_version = version("transformers")

    def to_dict(self) -> dict[str, Any]:
        """
        Convert config to dictionary representation.

        :return: Dictionary containing both PretrainedConfig and Pydantic fields
        """
        pretrained_dict = super().to_dict()
        model_dict = self.model_dump()
        config_dict = {**pretrained_dict, **model_dict}

        # strip all class variables and metadata that are not needed in the output
        for key in (
            "model_config",
            "auto_package",
            "registry_auto_discovery",
            "schema_discriminator",
            "model_type",
            "base_config_key",
            "sub_configs",
            "is_composition",
            "attribute_map",
            "base_model_tp_plan",
            "base_model_pp_plan",
            "_auto_class",
        ):
            config_dict.pop(key, None)

        return config_dict

    def to_diff_dict(self) -> dict[str, Any]:
        """
        Convert config to simplified dictionary representation.

        :return: Dictionary with only modified PretrainedConfig fields and all
            Pydantic fields
        """
        return super().to_diff_dict()


def reload_and_populate_configs():
    """
    Populate registries and reload schemas for configuration classes.

    Automatically discovers and registers all PydanticClassRegistryMixin subclasses
    and updates schemas to reflect current registry state.
    """
    TokenProposalConfig.auto_populate_registry()
    SpeculatorsConfig.reload_schema()
    SpeculatorModelConfig.auto_populate_registry()
