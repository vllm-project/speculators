# Entry Points (APIs, CLIs)

## What's Covered

In this document, you will learn:

1. How to interact with the Speculators toolkit through standardized CLI and Python API entry points.
2. How to convert to and use Speculator models.
3. The general design principles behind Speculators' entry points.

Before reading this document, you should be familiar with:

- Basic Python programming concepts
- Command-line interface usage
- Basic understanding of LLMs and the Hugging Face transformers/datasets libraries
- Basic understanding of what speculative decoding is and its benefits

## Overview

Speculators provides a set of standardized entry points for users to interact with the toolkit, enabling straightforward conversion, usage, and management of speculative decoding models. These entry points are designed to be intuitive, consistent, and extensible, regardless of the underlying speculative decoding algorithm. For users unfamiliar with the underlying architecture, these entry points abstract away the complexities of speculative decoding, allowing them to focus on their tasks without needing to understand the intricate details of the implementation. For implementers and researchers, these entry points provide a consistent interface for integrating new speculative decoding algorithms into the Speculators toolkit.

All CLI pathways are accessible under the base `speculators` command, which is installed with the package. The Python API entry points are available under the `speculators` namespace, allowing users to import and use them directly in their Python code. Additionally, the CLI and Python API entry points are designed to be equivalent in functionality and arguments where possible, enabling flexible usage depending on user preferences and requirements.

## Pathways

The core entry points for Speculators are organized in the sections below for easy navigation and reference. Each section describes the available entry points, their usage, and the underlying functionality they provide.

To view all available CLI commands, users can run:

```bash
speculators --help
```

This will display a list of all commands and their descriptions, providing an overview of the functionality available through the CLI.

To view all available Python imports, users can utilize [`pydoc`](https://docs.python.org/3/library/pydoc.html) by running the following commands:

```python
import pydoc
pydoc.help("speculators")
```

or

```bash
pydoc help speculators
```

### Convert

The conversion entry point allows users to convert existing models trained in other popular speculative decoding research libraries, such as Eagle and HASS, into the Speculators format. This enables users to leverage the benefits of the Speculators format and toolkit for further experimentation, training, and deployment.

Currently supported conversion sources include:

- Eagle v1, v2, v3: https://github.com/SafeAILab/EAGLE
- HASS: https://github.com/HArmonizedSS/HASS

The above sources are also generated by the pathways within the Speculators repository's `research` directory currently, which can be used to create the same models and convert them for vLLM deployment.

The conversion entry point is accessible through both the CLI and Python API:

```bash
speculators convert MODEL --algorithm ALGORITHM --verifier VERIFIER **KWARGS
```

```python
from speculators.convert import convert_model

convert_model(
    model=MODEL,
    algorithm=ALGORITHM,
    verifier=VERIFIER,
    **kwargs
)
```

The list of required/common arguments is as follows:

- `model`: The source model to convert, which can be a local directory, a Hugging Face Hub ID, or a URL pointing to the model files. For the CLI, this is a positional argument.
- `--verifier` or `verifier=`: The base model the speculator attaches to and uses for verification, which can also be a local directory, Hugging Face Hub ID, or URL.
- `--algorithm` or `algorithm=`: The conversion algorithm to use, such as `eagle` or `eagle3`. This specifies the conversion method to apply to the source model.
- `--output_path` or `output_path=`: The directory where the converted model will be saved. This defaults to saving in a directory named `converted` under the current working directory.

An example for converting a model using the entry point for an Eagle v1 model is as follows:

```bash
speculators convert "yuhuili/EAGLE-LLaMA3.1-Instruct-8B" \
    --algorithm eagle \
    --verifier "meta-llama/Llama-3.1-8B-Instruct"
```

```python
from speculators.convert import convert_model

convert_model(
    model="yuhuili/EAGLE-LLaMA3.1-Instruct-8B",
    algorithm="eagle",
    verifier="meta-llama/Llama-3.1-8B-Instruct"
)
```

For a full list of supported arguments, details, and examples on the conversion entry point, refer to the [convert documentation](./convert.md).
